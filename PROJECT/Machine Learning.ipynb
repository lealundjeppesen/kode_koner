{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1f1c32-fe79-4a76-b4a9-aa0ab8d561c2",
   "metadata": {},
   "source": [
    "## Machine Learning: Building a regression model using Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aecdac56-b75e-481d-a3b3-cd7204f6ddef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "## IMPORT VARIABLES OR DATA FRAMES HERE\n",
    "df_merged.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970aff9-5f83-470d-bf17-077dafedbd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into features and target variable\n",
    "X = df_merged[['mean', 'std', 'count']]  # Features\n",
    "y = df_merged['Daily_Return']  # Target variable\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Transforming the data set and creating interaction terms\n",
    "poly_trans = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_train_p = poly_trans.fit_transform(X_train)\n",
    "X_test_p = poly_trans.transform(X_test)  # Use transform, not fit_transform for the test set\n",
    "\n",
    "# Rescaling our data\n",
    "rescaler = StandardScaler().fit(X_train_p)\n",
    "X_train2 = rescaler.transform(X_train_p)\n",
    "X_test2 = rescaler.transform(X_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f98a689-9a46-48a9-a4f9-218bd4e15544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that calculates the mean squared error\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "output = []\n",
    "lambdas = np.logspace(-4, 4, 20)\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    reg = Lasso(alpha=lambda_, random_state=1)\n",
    "    reg.fit(X_train2, y_train)\n",
    "    output.append(\n",
    "        [\n",
    "            lambda_,\n",
    "            rmse(reg.predict(X_train2), y_train),\n",
    "            rmse(reg.predict(X_test2), y_test),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e826b1e-44a6-4d9b-aa4b-bb71654c502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization and selection of the optimal lambda cvalue\n",
    "MSE_df = pd.DataFrame(\n",
    "    data=output, columns=[\"lambda\", \"MSE train\", \"MSE test\"]\n",
    ").set_index(\"lambda\")\n",
    "\n",
    "MSE_df.plot(logx=True, logy=True)\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE for different lambda values')\n",
    "plt.show()\n",
    "\n",
    "best_fit = MSE_df[\"MSE test\"].nsmallest(1)\n",
    "lambda_opt, RMSE_min = next(best_fit.items())\n",
    "print(f\"Minimum RMSE = {RMSE_min:.3f} found for lambda = {lambda_opt:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcec91e-6fbe-4ff4-bc68-5de6ba05f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After fitting the Lasso model\n",
    "reg = Lasso(alpha=lambda_opt)\n",
    "reg.fit(X_train2, y_train)\n",
    "\n",
    "# Creating predicted values\n",
    "y_pred = reg.predict(X_test2)\n",
    "\n",
    "# Extracting coefficients and intercept\n",
    "coefficients = reg.coef_\n",
    "intercept = reg.intercept_\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Intercept:\", intercept)\n",
    "print(\"\\nCoefficients:\")\n",
    "for feature, coef in zip(poly_trans.get_feature_names_out(X.columns), coefficients):\n",
    "    print(f\"{feature}: {coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b317dc-9198-4b3f-a680-dea135951608",
   "metadata": {},
   "source": [
    "### Residuals Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37929dc-07ca-429a-b795-617bc51e1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plotting residuals\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')  # Adding a horizontal line at y=0\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d09409-9801-4644-b901-9377d95e61db",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9bb5d4-41ab-462c-9097-9dda858b066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the optimal lambda value\n",
    "reg = Lasso(alpha=lambda_opt)\n",
    "\n",
    "# Computing cross-validated RMSE scores\n",
    "scores = cross_val_score(reg, X_train2, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\"Cross-validated RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard Deviation of RMSE:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac8b8d7-367c-412b-9fed-5b85673c3c5b",
   "metadata": {},
   "source": [
    "#### Interpretation:\n",
    "\n",
    "Our model, on average, has an error of about 0.0234 (23,4%). This is the typical difference between the observed values and the model's predictions.\n",
    "\n",
    "The range of RMSE values across the 5 folds goes from around 0.017 to 0.036. This range gives you an idea of the best and worst-case scenarios for your model's performance on unseen data.\n",
    "\n",
    "The standard deviation of the RMSE values across the folds is 0.00675. This indicates that there's some variability in how well the model performs on different subsets of the data. If this value were very high, it might be a cause for concern, as it would indicate that the model's performance is very inconsistent. In your case, while there's some variability, it's not excessively high.\n",
    "\n",
    "In conclusion, cross-validation provides a more robust estimate of a model's performance than a single train-test split. By looking at the range and standard deviation of the RMSE values, you can get a sense of the model's consistency and reliability. If you're comparing multiple models, you'd typically choose the one with the lowest mean RMSE, provided its performance is consistent across folds (i.e., a low standard deviation of RMSE)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
